{"cells":[{"cell_type":"code","source":["!pip install datasets\n","!pip install transformers"],"metadata":{"id":"6XlZukxB7l1T"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bVtDdHKsdFIb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650878096037,"user_tz":-120,"elapsed":11203,"user":{"displayName":"Troels Jensen","userId":"10952173865704385677"}},"outputId":"7189ed66-a7ee-42ea-ac24-ae8f11b598a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from datasets import load_metric, Dataset\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","from transformers import TrainingArguments, Trainer, DataCollatorWithPadding, AutoModelForSequenceClassification, AutoTokenizer\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#Load model and tokenizer"],"metadata":{"id":"qcMM1aTx7798"}},{"cell_type":"code","source":["model_name = \"distilbert-base-uncased\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wiNN91X737j","executionInfo":{"status":"ok","timestamp":1650878099138,"user_tz":-120,"elapsed":3110,"user":{"displayName":"Troels Jensen","userId":"10952173865704385677"}},"outputId":"ac1738e1-9f8e-4efd-9326-6696a9bf099e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","metadata":{"id":"OC2kiG8NdFIh"},"source":["# Load and preprocess Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CaTfxoOfdFIc"},"outputs":[],"source":["path = \"/content/drive/MyDrive/Colab Notebooks/data/SARC_filtered_40K.csv\"\n","data = pd.read_csv(path, encoding='utf-8').dropna()\n","df = pd.concat([data[\"comment\"],data[\"label\"]], axis = 1)\n","ds = Dataset.from_pandas(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uqp4e7VVdFIi","outputId":"43467fd7-fefd-4d3e-caaf-27cef2ab0999","colab":{"referenced_widgets":["f24eacc09b1d4205b646d101486b8eb7","8884922b87ad435d913ff0472ee0057b","b0bf621a7d4c4ae9be0ecff198b34375","901299b8a11f4fffa78a36b105b60509","023c3cbe054a46a09fd0d030e9366f7c","f5eb716e2b914f7db26c7d6951dee7f4","5edf802022f642cbb78d41e9c8f1348c","43aba78c34e149fe94cad973079e6b5d","f2852688a8af48899255d19f12b50533","89b01527a2bf4d4fab3879482f935615","3419f92ed77c4e229ec532df39a84f4b"],"base_uri":"https://localhost:8080/","height":49},"executionInfo":{"status":"ok","timestamp":1650878102399,"user_tz":-120,"elapsed":3267,"user":{"displayName":"Troels Jensen","userId":"10952173865704385677"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/37 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f24eacc09b1d4205b646d101486b8eb7"}},"metadata":{}}],"source":["def tokenize(examples):\n","    outputs = tokenizer(examples['comment'], truncation=True)\n","    return outputs\n","\n","tokenized_ds = ds.map(tokenize, batched=True)\n","split_tokenized_ds = tokenized_ds.train_test_split(test_size=0.2)"]},{"cell_type":"markdown","metadata":{"id":"QRbrxInndFIj"},"source":["# Prepare Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EFF8jqOEdFIk"},"outputs":[],"source":["def compute_metrics(eval_preds):\n","    metric = load_metric(\"accuracy\")\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vc9vNkE5dFIl"},"outputs":[],"source":["training_args = TrainingArguments(num_train_epochs=4,\n","                                  output_dir=\"distilbert_SARC\",\n","                                  per_device_train_batch_size=64,\n","                                  per_device_eval_batch_size=64,\n","                                  save_strategy=\"epoch\",\n","                                  evaluation_strategy ='epoch',\n","                                  load_best_model_at_end=True,)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V3ntGPnadFIm"},"outputs":[],"source":["data_collator = DataCollatorWithPadding(tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTshlMOUdFIm"},"outputs":[],"source":["trainer = Trainer(model=model, tokenizer=tokenizer,\n","                  data_collator=data_collator,\n","                  args=training_args,\n","                  train_dataset=split_tokenized_ds[\"train\"],\n","                  eval_dataset=split_tokenized_ds[\"test\"], \n","                  compute_metrics=compute_metrics)"]},{"cell_type":"markdown","metadata":{"id":"yyQVElbjdFIn"},"source":["# Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kgYQBznwdFIn","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1650878613061,"user_tz":-120,"elapsed":379574,"user":{"displayName":"Troels Jensen","userId":"10952173865704385677"}},"outputId":"57dbe2d6-b40f-4352-8a59-6fc973006904"},"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, comment. If __index_level_0__, comment are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 29358\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1377\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1377/1377 06:19, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>250</td>\n","      <td>No log</td>\n","      <td>0.482258</td>\n","      <td>0.772480</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.507900</td>\n","      <td>0.498521</td>\n","      <td>0.782970</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.507900</td>\n","      <td>0.474416</td>\n","      <td>0.786512</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.373900</td>\n","      <td>0.535792</td>\n","      <td>0.783924</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.373900</td>\n","      <td>0.535500</td>\n","      <td>0.781880</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, comment. If __index_level_0__, comment are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 7340\n","  Batch size = 64\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, comment. If __index_level_0__, comment are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 7340\n","  Batch size = 64\n","Saving model checkpoint to distilbert_SARC/checkpoint-500\n","Configuration saved in distilbert_SARC/checkpoint-500/config.json\n","Model weights saved in distilbert_SARC/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in distilbert_SARC/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in distilbert_SARC/checkpoint-500/special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, comment. If __index_level_0__, comment are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 7340\n","  Batch size = 64\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, comment. If __index_level_0__, comment are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 7340\n","  Batch size = 64\n","Saving model checkpoint to distilbert_SARC/checkpoint-1000\n","Configuration saved in distilbert_SARC/checkpoint-1000/config.json\n","Model weights saved in distilbert_SARC/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in distilbert_SARC/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in distilbert_SARC/checkpoint-1000/special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, comment. If __index_level_0__, comment are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 7340\n","  Batch size = 64\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from distilbert_SARC/checkpoint-500 (score: 0.49852117896080017).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1377, training_loss=0.3920303488781942, metrics={'train_runtime': 379.3938, 'train_samples_per_second': 232.144, 'train_steps_per_second': 3.629, 'total_flos': 1238583113703000.0, 'train_loss': 0.3920303488781942, 'epoch': 3.0})"]},"metadata":{},"execution_count":11}],"source":["trainer.train()"]},{"cell_type":"markdown","source":["#Save model and tokenizer"],"metadata":{"id":"ydJNP--G8LpM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OCvzkWqpdFIo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650878699510,"user_tz":-120,"elapsed":4240,"user":{"displayName":"Troels Jensen","userId":"10952173865704385677"}},"outputId":"0ea5ce00-9780-4146-9037-801576aa7de0"},"outputs":[{"output_type":"stream","name":"stderr","text":["Configuration saved in /content/drive/MyDrive/Colab Notebooks/saved_models/Distilbert_SARC/config.json\n","Model weights saved in /content/drive/MyDrive/Colab Notebooks/saved_models/Distilbert_SARC/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/Colab Notebooks/saved_models/Distilbert_SARC/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/Colab Notebooks/saved_models/Distilbert_SARC/special_tokens_map.json\n"]},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/Colab Notebooks/saved_models/Distilbert_SARC/tokenizer_config.json',\n"," '/content/drive/MyDrive/Colab Notebooks/saved_models/Distilbert_SARC/special_tokens_map.json',\n"," '/content/drive/MyDrive/Colab Notebooks/saved_models/Distilbert_SARC/vocab.txt',\n"," '/content/drive/MyDrive/Colab Notebooks/saved_models/Distilbert_SARC/added_tokens.json',\n"," '/content/drive/MyDrive/Colab Notebooks/saved_models/Distilbert_SARC/tokenizer.json')"]},"metadata":{},"execution_count":12}],"source":["model_save_name = 'Distilbert_SARC'\n","model.save_pretrained(F\"/content/drive/MyDrive/Colab Notebooks/saved_models/{model_save_name}\")\n","tokenizer.save_pretrained(F\"/content/drive/MyDrive/Colab Notebooks/saved_models/{model_save_name}\")"]},{"cell_type":"code","source":[""],"metadata":{"id":"5r6O-CFPCcRz"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"colab":{"name":"SARC_Distilbert","provenance":[{"file_id":"https://github.com/lvwerra/trl/blob/master/nbs/03-distilbert-imdb-training.ipynb","timestamp":1646758511776}]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f24eacc09b1d4205b646d101486b8eb7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8884922b87ad435d913ff0472ee0057b","IPY_MODEL_b0bf621a7d4c4ae9be0ecff198b34375","IPY_MODEL_901299b8a11f4fffa78a36b105b60509"],"layout":"IPY_MODEL_023c3cbe054a46a09fd0d030e9366f7c"}},"8884922b87ad435d913ff0472ee0057b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5eb716e2b914f7db26c7d6951dee7f4","placeholder":"​","style":"IPY_MODEL_5edf802022f642cbb78d41e9c8f1348c","value":"100%"}},"b0bf621a7d4c4ae9be0ecff198b34375":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43aba78c34e149fe94cad973079e6b5d","max":37,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2852688a8af48899255d19f12b50533","value":37}},"901299b8a11f4fffa78a36b105b60509":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89b01527a2bf4d4fab3879482f935615","placeholder":"​","style":"IPY_MODEL_3419f92ed77c4e229ec532df39a84f4b","value":" 37/37 [00:02&lt;00:00, 11.99ba/s]"}},"023c3cbe054a46a09fd0d030e9366f7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5eb716e2b914f7db26c7d6951dee7f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5edf802022f642cbb78d41e9c8f1348c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43aba78c34e149fe94cad973079e6b5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2852688a8af48899255d19f12b50533":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89b01527a2bf4d4fab3879482f935615":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3419f92ed77c4e229ec532df39a84f4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}